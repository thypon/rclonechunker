#!/bin/bash
# rclonechunker: Tool to segment and upload large files with rclone
# (c) 2018 Michael Barrow <michael@barrow.me>
#
# 2018-07-03
#
# MIT License
#
# Copyright (c) 2018 Michael Barrow
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Default chunk size is 200 MiB
defaultChunkSize=209715200
defaultMaxRetries=10

# Number of simultaneous uploads
defaultParallelOps=8

# Arguments
file=$1
dest=$2
chunkSize=$3
maxRetries=$4
parallelOps=$5

baseName=$(basename "$file")

usage()
{
  echo "Usage: $0 {filename} {rclone remote:path} [{chunk size in bytes}] [{maximum retries to upload before exiting}] [{parallel operations}]"
  echo "   chunk size defaults to $defaultChunkSize"
  exit 1
}

# Check the arguments
[ -h "$file" ] && file=$(readlink -f "$file")
[ -z "$file" ] && { echo "Missing filename"; usage; }
if [ -f "$file" ]; then
  fileSize=$(ls -l "$file" | awk '{print $5}')
elif [ -b "$file" ]; then
  fileSize=$(df -B1 "$file" | tail -n1 | awk '{print $2}')
else
  echo "$file is not a regular file, nor a block device"; usage
fi
[ -z "$chunkSize" ] && chunkSize=$defaultChunkSize
[ -z "$maxRetries" ] && maxRetries=$defaultMaxRetries
[ -z "$parallelOps" ] && parallelOps=$defaultParallelOps

# Let's go!
chunkSuffix=_CHUNKED_FILE_

[ -z "$fileSize" ] && { echo "File size does not look right!"; exit 1; }

if [ $fileSize -lt $chunkSize ]
then
  echo "File is smaller than chunksize ($chunkSize)...exiting..."
  exit 1
fi

((chunkCount=fileSize / chunkSize))
((lastChunkSize=fileSize % chunkSize))
if [ $lastChunkSize -ne 0 ]
then
  ((chunkCount++))
fi

echo "Splitting $file into $chunkCount chunks of $chunkSize bytes and uploading to $dest"

thisChunk=0
chunkName="$dest/${baseName}$chunkSuffix"
compressProgram="lz4 -9 -" # use 'cat' for no compression
checksumProgram="sha256sum"
localStateDir="$HOME/.rclonechunker/state/" # use '' for remote state
stateDir="$localStateDir/$chunkName/state"

function checksum() {
  checksumProgram="sha256sum"
  dd if="$1" bs=$chunkSize skip=$thisChunk count=1 2>/dev/null | $checksumProgram | awk '{print $1}'
}

[ "$RCLONE_PURGE_STATE" = "yes" ] && rclone purge ${stateDir}

while true; do
  while [ $thisChunk -lt $chunkCount ]
  do
    echo -n "Chunk #${thisChunk}..."
    chunkFile="$chunkName/${thisChunk}"
    doneFile="$stateDir/${thisChunk}.DONE"
    checksumDone=$(rclone cat "${doneFile}" 2>/dev/null)
    checksumLocal=$(checksum "$file")
    if ! [ "$checksumDone" = "$checksumLocal" ]
    then
      ((jobCtrl = jobCtrl % parallelOps)); ((jobCtrl++ == 0)) && wait
      echo "uploading"
      (dd if="$file" bs=$chunkSize skip=$thisChunk count=1 2>/dev/null | $compressProgram | rclone rcat "$chunkFile" && checksum "$file" | rclone rcat "${doneFile}") &
    else
      echo "skipping -- already present"
    fi
    ((thisChunk++))
  done
  completedChunks=$(rclone ls $localStateDir 2>& /dev/null | wc -l)
  ((maxRetries--))
  [ $completedChunks -ge $chunkCount ] && break
  [ $maxRetries -le 0 ] && break
done

echo "DONE!"
exit
